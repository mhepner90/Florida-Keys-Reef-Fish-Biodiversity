---
title: "hepner_et_al_2018"
author: "Megan Hepner"
date: "November 5, 2017"
output: html_document
---

Library's used to compute diversity indices, statistical test, and to produce plots 

```{r librarys}

library(AICcmodavg) #AIC
library(ade4) #mantel.rtest
library(ape) #read.tree, as.phylo 
library(clue) #cl_consensus, cl_ultrametric, cl_dissimilarity,cl_ultrametric
library(cowplot) #get_legend 
library(d3treeR) #d3treeR interactive traitmap
library(devtools) #install_github
library(FD) #gowdis
library(fpc) #pamk
library(FSA) #dunnTest
library(ggplot2) #ggplot
library(grid)
library(gridExtra) #grid.arrange
library(htmlwidgets) #save interactive treemap and pie chart 
library(lattice)
library(magrittr) # %$%
library(MASS)# contains boxcox function
library(mgcv) #gam
library(moments) # contains skewness function
library(nortest) #checks for normality 
library(parallel) #clusterEvalQ,clusterExport,detectCores,makeCluster,parLapply
library(plotrix) #std.error
library(psych) #pairs.panels 
library(purrr) #map
library(rcompanion) #cldList
library(readr) #saveRDS, read_rds, readRDS 
library(reshape2) #melt
#devtools::install_github('jeremiaheb/rvc')
library(rpsychi) #statistical tests using summary data
library(rvc) #getPSUAbundance, getStrataAbundance, getDomainAbundance 
library(tidyverse) #select, filter, mutate, group_by, summarize 
library(treemap) #treemap
library(vegan) #spec, diversity 
library(webshot) #screenshot of interactive treemap and pie chart

map = purrr::map # override maps::map
select = dplyr::select #override MASS::select 
group_by =  dplyr::group_by #override plotly::group_by
summarise = dplyr::summarise #override plotly::summarise
```

Fetch abundance data for each primary sampling unit (PSU) from 1999 - 2016 

```{r fetch abundance data}

if(!file.exists("psu_fk_abun.csv")){
  
  fk_data <- getRvcData(1999:2016, "FLA KEYS", server = 'https://www.sefsc.noaa.gov/rvc_analysis20/')
  
  spp_list<- fk_data$taxonomic_data$COMNAME #399 species 
  write_csv(spp_list, 'spp_list.csv')
  
  fk1999<- getRvcData(1999, "FLA KEYS", server = 'https://www.sefsc.noaa.gov/rvc_analysis20/')
  psu_abunfk1999 <- getPSUAbundance(fk1999, spp_list, merge_protected = F)
  write_csv(psu_abunfk1999, 'psu_abunfk1999.csv') #1999
  
  fk2000<- getRvcData(2000, "FLA KEYS", server = 'https://www.sefsc.noaa.gov/rvc_analysis20/')
  psu_abunfk2000 <- getPSUAbundance(fk2000, spp_list, merge_protected = F)  
  write_csv(psu_abunfk2000, 'psu_abunfk2000.csv') #2000

  fk2001<- getRvcData(2001, "FLA KEYS", server = 'https://www.sefsc.noaa.gov/rvc_analysis20/')
  psu_abunfk2001 <- getPSUAbundance(fk2001, spp_list, merge_protected = F) 
  write_csv(psu_abunfk2001, 'psu_abunfk2001.csv') #2001
  
  fk2002<- getRvcData(2002, "FLA KEYS", server = 'https://www.sefsc.noaa.gov/rvc_analysis20/')
  psu_abunfk2002 <- getPSUAbundance(fk2002, spp_list, merge_protected = F) 
  write_csv(psu_abunfk2002, 'psu_abunfk2002.csv') #2002
  
  fk2003<- getRvcData(2003, "FLA KEYS", server = 'https://www.sefsc.noaa.gov/rvc_analysis20/')
  psu_abunfk2003 <- getPSUAbundance(fk2003, spp_list, merge_protected = F) 
  write_csv(psu_abunfk2003, 'psu_abunfk2003.csv') #2003
  
  fk2004<- getRvcData(2004, "FLA KEYS", server = 'https://www.sefsc.noaa.gov/rvc_analysis20/')
  psu_abunfk2004 <- getPSUAbundance(fk2004, spp_list, merge_protected = F)
  write_csv(psu_abunfk2004, 'psu_abunfk2004.csv') #2004
  
  fk2005<- getRvcData(2005, "FLA KEYS", server = 'https://www.sefsc.noaa.gov/rvc_analysis20/') 
  psu_abunfk2005 <- getPSUAbundance(fk2005, spp_list, merge_protected = F) 
  write_csv(psu_abunfk2005, 'psu_abunfk2005.csv') #2005
  
  fk2006<- getRvcData(2006, "FLA KEYS", server = 'https://www.sefsc.noaa.gov/rvc_analysis20/') 
  psu_abunfk2006 <- getPSUAbundance(fk2006, spp_list, merge_protected = F) 
  write_csv(psu_abunfk2006, 'psu_abunfk2006.csv') #2006
  
  fk2007<- getRvcData(2007, "FLA KEYS", server = 'https://www.sefsc.noaa.gov/rvc_analysis20/') psu_abunfk2007 <- getPSUAbundance(fk2007, spp_list, merge_protected = F) 
  write_csv(psu_abunfk2007, 'psu_abunfk2007.csv') #2007
  
  fk2008<- getRvcData(2008, "FLA KEYS", server = 'https://www.sefsc.noaa.gov/rvc_analysis20/') psu_abunfk2008 <- getPSUAbundance(fk2008, spp_list, merge_protected = F) 
  write_csv(psu_abunfk2008, 'psu_abunfk2008.csv') #2008
  
  fk2009<- getRvcData(2009, "FLA KEYS", server = 'https://www.sefsc.noaa.gov/rvc_analysis20/')
  psu_abunfk2009 <- getPSUAbundance(fk2009, spp_list, merge_protected = F) 
  write_csv(psu_abunfk2009, 'abundance_psu/FK/psu_abunfk2009.csv') #2009 
  
  fk2010<- getRvcData(2010, "FLA KEYS", server = 'https://www.sefsc.noaa.gov/rvc_analysis20/')
  psu_abunfk2010 <- getPSUAbundance(fk2010, spp_list, merge_protected = F) 
  write_csv(psu_abunfk2010, 'abundance_psu/FK/psu_abunfk2010.csv') #2010
  
  fk2011<- getRvcData(2011, "FLA KEYS", server = 'https://www.sefsc.noaa.gov/rvc_analysis20/')
  psu_abunfk2011 <- getPSUAbundance(fk2011, spp_list, merge_protected = F) 
  write_csv(psu_abunfk2011, 'big_csv/abundance_psu/FK/psu_abunfk2011.csv') #2011
  
  fk2012<- getRvcData(2012, "FLA KEYS", server = 'https://www.sefsc.noaa.gov/rvc_analysis20/')
  psu_abunfk2012 <- getPSUAbundance(fk2012, spp_list, merge_protected = F)
  write_csv(psu_abunfk2012, 'abundance_psu/FK/psu_abunfk2012.csv') #2012
  
  fk2014<- getRvcData(2014, "FLA KEYS", server = 'https://www.sefsc.noaa.gov/rvc_analysis20/') 
  psu_abunfk2014 <- getPSUAbundance(fk2014, spp_list, merge_protected = F) 
  write_csv(psu_abunfk2014, 'abundance_psu/FK/psu_abunfk2014.csv') #2014
  
  fk2016<- getRvcData(2016, "FLA KEYS", server = 'https://www.sefsc.noaa.gov/rvc_analysis20/')
  psu_abunfk2016 <- getPSUAbundance(fk2016, spp_list, merge_protected = F) 
  write_csv(psu_abunfk2016, 'psu_abunfk2016.csv') #2016

#Bind PSU abundance data from 1999 - 2016 in the Florida Keys into one csv file

  ##FK abundance psu 
  cat("bind all csv's\n") #concatenate and print - character string naming the file to print to
  d = data_frame()
  for (f in list.files('big_csv/abundance_psu/FK', pattern="*.csv", full.names=T)){
    cat(' ', f,'\n')
    d_f = read_csv(
      f, #path to a file 
      progress=F, #progress: Display a progress bar
      trim_ws=T, #trim_ws: leading and trailing whitespace are trimmed 
      col_types = cols(
        protected_status = col_character()))  #column specification - must contain one column specification for each column
    d = bind_rows(d, d_f)
  } 
  write_csv(d, 'psu_fk_abun.csv') 
  }else{
  psu_abundance = read_csv("psu_fk_abun.csv",
                           col_types = cols(protected_status = col_character()))
}

```

#Clean data 

Cleaned the data by:
- removed sampling events with no individuals
- removed sampling events with only 1 individuals
- removed species not identified to species level (e.g., genus)
- removed sampling events with uncharactertistically large abundance values 
- removed species that did not occur in at least 5% of the entire dateset

Left with 108 species of reef fish and 5,235 sampling events between 1999 and 2016 

```{r clean up data }

if(!file.exists("clean_data.csv")){
  #read in data 
  psu_abundance <- read_csv("psu_fk_abun.csv",
                            col_types = cols(protected_status = col_character()))
  #dim(psu_fk_abun) #3,643,306 x 10
  
  #remove species not identified in species level 
  clean_data = psu_abundance %>%
    filter(!stringr::str_detect(SPECIES_CD, 'SPE\\.$'))%>% #348 species
    filter(stringr::str_detect(protected_status, 'all'))%>% #dim(psu_abundance) 1,689,982x10
    filter(!abundance == "0")
  #dim(psu_abundance) 203,466     10
  
  #remove species that occured in less than 5% of PSU's (total of 5,234 sampling events between 1999-2016). Species must have occured at least 262 sampling events.
  remove_rare_sp = clean_data %>%
    mutate(presence_absence = 
             ifelse(abundance == 0, "0",
                    ifelse(abundance >0, "1", "IDK")))%>%
    group_by(SPECIES_CD)%>%
    summarise(
      occurance = sum(as.numeric(presence_absence)))%>%
    arrange(occurance)%>%
    filter(occurance > 261) #108 species 
  
  if(!file.exists('RVCdata_FK.rds')){
    RVCdata_FK = getRvcData(1999:2016, "FLA KEYS", server = "https://www.sefsc.noaa.gov/rvc_analysis20/")
  }else{
    RVCdata_FK = read_rds("RVCdata_FK.rds")
  }
  
  taxonimic_data = RVCdata_FK$taxonomic_data
  
  species_occured_5_percent_data = left_join(remove_rare_sp,taxonimic_data, by="SPECIES_CD")%>%
    select(SPECIES_CD,FAMILY,SCINAME,COMNAME) #108 x 4 
  
  #remove species from abundance data didn't occur 5% of the sampling events 
  clean_data = left_join(clean_data, species_occured_5_percent_data, by="SPECIES_CD") 
  #dim(clean_data) 192,780x13 (108 species)
  
  #remove PSU with only 1 species [2006,602U INPR] [2016,  1010U, INPR] and remove 2001 PSU 222U HRRF with abundance 5X greater than normal 
  clean_data = clean_data[!(clean_data$YEAR == "2006" & 
                              clean_data$PRIMARY_SAMPLE_UNIT == "602U" | #only 1 species
                              clean_data$YEAR == "2016" & 
                              clean_data$PRIMARY_SAMPLE_UNIT == "1010U"| #only 1 species 
                              clean_data$YEAR == "2002" &
                              clean_data$PRIMARY_SAMPLE_UNIT =="472U"  | #one large school sp.
                              clean_data$YEAR == "2003" &
                              clean_data$PRIMARY_SAMPLE_UNIT =="119U"  | #one large school sp. 
                              clean_data$YEAR == "2004" &
                              clean_data$PRIMARY_SAMPLE_UNIT =="403U"  | #one large school sp.
                              clean_data$YEAR == "2001" & 
                              clean_data$PRIMARY_SAMPLE_UNIT =="222U"),]
  #INPR_2002_472U - HYP HARR abundance 9999.5 
  #OFPR_2003_119U - DEC PUNC abundance 5000.0
  #MCPR_2004_403U - HYP HARR abundance 5000.0
  #FMLR_2001_222U - ATH STIP abundance 10,000.0 
  #dim(clean_data) 192,780 x 10
  
  write_csv(clean_data, "clean_data.csv")
  
}else{
  clean_data = read_csv("clean_data.csv", 
                        col_types = cols(protected_status = col_character()))
}

```

Species-trait matrix

```{r species-trait matrix}

if (!file.exists("functional_distance_rds")){
  
  trait_matrix = read_csv('species_trait_matrix_316_spp_10_25_17.csv')
  
  trait_matrix = trait_matrix %>%
    as.tibble() %>%
    mutate(
      SPECIES_CD = toupper(as.character(SPECIES_CD))) 
  
  species_108 = read_csv("species_5_percent_data.csv") #species that occured in >5% of the sample data 
  
  species_trait_matrix = dplyr::semi_join(trait_matrix, species_108, by="SPECIES_CD") #108*12
  
  write_csv(species_trait_matrix, "species_trait_matrix.csv")
  
  trait_matrix = species_trait_matrix %>%
    as.tibble() %>%
    mutate(
      SPECIES_CD = toupper(as.character(SPECIES_CD))) %>% 
    arrange(SPECIES_CD)%>% 
    select(SPECIES_CD, Maxlength, Trophic_level, Trophic_group, Water_column, Diel_activity, Substrate_type, Complexity, Gregariousness) %>% #348*9
    group_by(
      SPECIES_CD, Maxlength, Trophic_level, Trophic_group, Water_column, Diel_activity, Substrate_type, Complexity, Gregariousness) %>%
    #summarize(n = n()) %>%
    #select(-n) %>%
    ungroup() %>%
    mutate(
      # ordinal traits
      Complexity = ordered(Complexity, levels=c("Low","Medium","High")),
      Gregariousness = ordered(Gregariousness, levels=c("1","2","3"))) %>%
    as.data.frame()
  
  #Set species names as row.names and remove extra columns
  rownames(trait_matrix)=trait_matrix$SPECIES_CD 
  
  #Calculate Gower distances. Variables have equal weight. 
  traits.dist = gowdis(trait_matrix, ord="podani")
  
  #to account for sensitivity in clustering use multiple algorithms  (Mouchet et al., 2008) 
  tree_methods = c("single","complete","average","mcquitty","ward.D") #average is best clustering method 
  trees=lapply(tree_methods,  function(i) hclust(traits.dist, method=i))
  par(mfrow=c(3,2))
  for(i in 1:length(trees)) {plot(trees[[i]])} #plots the 5 different kinds of trees 
  trees.ultra= lapply(trees,function(i) cl_ultrametric(as.hclust(i)))
  
  #Plot each tree
  par(mfrow=c(3,2))
  for (i in 1:length(trees.ultra)) {plot(trees.ultra[[i]])}  #plots the 5 different kinds of trees 
  
  #Build the consensus tree (Mouchet et al 2008 Oikos)  
  ensemble.trees=cl_ensemble(list=trees) #list of clusterings 
  class(ensemble.trees)
  consensus.tree=cl_consensus(ensemble.trees) #synthesizes the information in the elements of a cluster ensemble into a single clustering 
  par(mar=c(1,1,1,1))
  plot(consensus.tree, horiz=T)
  
  #Calculate dissimilarity values for each tree using 2-norm (Merigot et al 2010 Ecology) to determine which tree best preserves orignial distances 
  #spectral norm (2-norm) of the differences of the ultrametrics
  all.trees=c(trees.ultra,consensus.tree[1])
  names(all.trees)=c(tree_methods,"consensus")
  (trees.dissim=lapply(all.trees,function(i) cl_dissimilarity(i,traits.dist,method="spectral"))) 
  #Identify best tree and isolate
  trees.dissim2=do.call(rbind,trees.dissim)
  min.tree=which.min(trees.dissim2) #average 
  names(all.trees)[min.tree]
  func.dist=all.trees[names(all.trees)==names(all.trees)[min.tree]][[1]]
  #Confirm lowest 2-norm value,  spectral norm (2-norm) of the differences if the ultrametrics 
  cl_dissimilarity(func.dist,traits.dist,method="spectral") #Cross-dissimilarities using spectral ultrametric distance:   4.760895
  
  #Scale by the max value so that all values are between 0-1
  func.dist=func.dist/max(func.dist)
  saveRDS(func.dist, "functional_distance_rds")
}else{ #read data 
  func.dist = read_rds("functional_distance_rds")
} 

if(!file.exists("functional_distance_common_rds")){
  
  trait_matrix_common = trait_matrix %>%
    as.tibble() %>%
    mutate(
      Common_name = toupper(as.character(Common_name))) %>% 
    arrange(Common_name)%>% 
    select(Common_name, Maxlength, Trophic_level, Trophic_group, Water_column, Diel_activity, Substrate_type, Complexity, Gregariousness) %>% #348*9
    group_by(
      Common_name, Maxlength, Trophic_level, Trophic_group, Water_column, Diel_activity, Substrate_type, Complexity, Gregariousness) %>%
    #summarize(n = n()) %>%
    #select(-n) %>%
    ungroup() %>%
    mutate(
      # ordinal traits
      Complexity = ordered(Complexity, levels=c("Low","Medium","High")),
      Gregariousness = ordered(Gregariousness, levels=c("1","2","3"))) %>%
    as.data.frame()
  
  #Set species names as row.names and remove extra columns
  rownames(trait_matrix_common)=trait_matrix_common$Common_name 
  
  #Calculate Gower distances. Variables have equal weight. 
  traits.dist.common = gowdis(trait_matrix_common, ord="podani")
  
  trees_common=lapply(tree_methods,  function(i) hclust(traits.dist, method=i))
  
  trees_ultra_common= lapply(trees_common,function(i) cl_ultrametric(as.hclust(i)))
  
  #Plot each tree
  par(mfrow=c(3,2))
  for (i in 1:length(trees_ultra_common)) {plot(trees_ultra_common[[i]])} #plots the 5 different kinds of trees 
  
  ensemble.trees=cl_ensemble(list=trees) #list of clusterings 
  class(ensemble.trees)
  consensus.tree=cl_consensus(ensemble.trees) #synthesizes the information in the elements of a cluster ensemble into a single clustering 
  par(mar=c(1,1,1,1))
  plot(consensus.tree, horiz=T)
  
  all.trees=c(trees_ultra_common,consensus.tree[1])
  names(all.trees)=c(tree_methods,"consensus")
  (trees.dissim=lapply(all.trees,function(i)
    cl_dissimilarity(i,traits.dist.common,method="spectral"))) 
  
  #Identify best tree and isolate
  trees.dissim2=do.call(rbind,trees.dissim)
  min.tree=which.min(trees.dissim2) #average 
  names(all.trees)[min.tree]
  func.dist.common=all.trees[names(all.trees)==names(all.trees)[min.tree]][[1]]
  cl_dissimilarity(func.dist.common,traits.dist.common,method="spectral")
  #Cross-dissimilarities using spectral ultrametric distance:
  
  #Scale by the max value so that all values are between 0-1
  func.dist.common=func.dist.common/max(func.dist.common)
  saveRDS(func.dist.common, "functional_distance_common_rds")
}else{
  func.dist.common = readRDS("functional_distance_common_rds")
}


```

Compute diversity indices 

```{r biodiversity}

if(!file.exists('diversity_data.csv')){
  
  clean_data = read_csv("clean_data.csv")
  
  species_trait_matrix = read_csv("species_trait_matrix.csv") %>%
    as.data.frame()
  
  diversity_indices = clean_data %>%  
    select(YEAR, PRIMARY_SAMPLE_UNIT,STRAT,PROT,SPECIES_CD,abundance) %>% #tibble: 192,780 x 6
    group_by(YEAR, PRIMARY_SAMPLE_UNIT, STRAT, PROT) %>% #5,235 groups 
    nest(-YEAR) %>%
    mutate(
      data_wide = map(data, function(x) 
        full_join(x, species_trait_matrix %>% select(SPECIES_CD), by='SPECIES_CD') %>%
          mutate(abundance = ifelse(is.na(abundance), 0, abundance)) %>%
          spread(SPECIES_CD, abundance, fill =0)),
      data_wide = map(data, ~ spread(data=.x, SPECIES_CD, abundance, fill =0)), 
      richness = map( #species richness
        data_wide, 
        function(x) specnumber(x)),
      simpson = map( #simpson diversity as effective number of species 
        data_wide,
        function(x) 1/(1 - diversity(x, index = 'simpson'))),
      shannon = map( #shannon diversity as effective number of species 
        data_wide, 
        function(x) exp(diversity(x,  index = 'shannon')))) %>% 
    unnest(richness, simpson, shannon)
  
  diversity_indices = diversity_indices %>%
    select(YEAR,PRIMARY_SAMPLE_UNIT,STRAT,PROT,richness,simpson,shannon) %>%
    mutate(simpson = round(simpson,8),
           shannon = round(shannon,8))
  #dim(diversity_indices) 5235x7
  
  func.dist = read_rds("functional_distance_rds")
  
  #Set rownames on traits and remove other info
  rownames(species_trait_matrix) <- species_trait_matrix$SPECIES_CD
  species_trait_matrix <- species_trait_matrix[, -c(1:4)]
  #Convert rownames to all caps
  rownames(species_trait_matrix) <- toupper(rownames(species_trait_matrix))
  
  abundance = clean_data %>%
    select(YEAR, PRIMARY_SAMPLE_UNIT,STRAT,PROT, SPECIES_CD, abundance) %>% 
    group_by(YEAR, PRIMARY_SAMPLE_UNIT,STRAT,PROT)
  #dim(abundance) 192780x6 : 5235 groups 
  
  #Cast abundance longways (species as columns)
  abundmat <- spread(abundance, SPECIES_CD, abundance, fill = 0) 
  #dim(abundmat)5,235*112
  
  #Subset species whose names only appear in traits
  abundmat <- abundmat[colnames(abundmat) %in% rownames(species_trait_matrix)] 
  #dim(abundmat) #5,235 x 108
  
  #Calculate relative values for community matrix
  rel.mat=abundmat/apply(abundmat,1,sum)
  
  #Compute species diversity
  species.dist=matrix(1,ncol(abundmat),ncol(abundmat))-diag(rep(1,ncol(abundmat))) 
  simpson=1/(1-apply(rel.mat,1,function(x) t(x) %*% species.dist %*% x))
  
  #Compute evenness (as in Jost 2010 Diversity)
  evenness=log(simpson)/log(rowSums(abundmat>0))
  
  #functional diversity 
  func.div=1/(1-apply(rel.mat,1, function(x) t(x) %*% as.matrix(func.dist) %*% x))
  
  #Bind all to the original dataframe 
  list = cbind(simpson,func.div,evenness) %>%
    as_tibble()%>%
    mutate(simpson = round(simpson,8),
           func.div = round(func.div, 8),
           evenness = round(evenness, 8))
  #dim(list) 5235x3
  
  diversity = left_join(diversity_indices, list, by="simpson") %>%
    group_by(YEAR, PRIMARY_SAMPLE_UNIT) %>% #5,235 groups
    summarise(
      richness = first(richness),
      simpson = first(simpson),
      shannon = first(shannon),
      func.div = first(func.div),
      evenness = first(evenness))
  
  RVC_data = read_rds("RVCdata_FK.rds")
  sample_data = RVCdata_FK$sample_data %>%
    as.tibble() %>%
    select(-SPECIES_CD, -SPECIES_NR, -REGION, -TIME_SEEN, -LEN, -NUM)%>%
    group_by(YEAR,PRIMARY_SAMPLE_UNIT, STRAT, PROT, MPA_NR)%>% 
    summarize(
      LAT_DEGREES = mean(LAT_DEGREES),
      LON_DEGREES = mean(LON_DEGREES),
      DEPTH = mean(DEPTH),
      MONTH = mean(MONTH))
  #dim 5,241X8
  
  sample_data = sample_data[!(sample_data$YEAR == "2006" & 
                              sample_data$PRIMARY_SAMPLE_UNIT == "602U" | #only 1 species
                              sample_data$YEAR == "2016" & 
                              sample_data$PRIMARY_SAMPLE_UNIT == "1010U"| #only 1 species 
                              sample_data$YEAR == "2002" &
                              sample_data$PRIMARY_SAMPLE_UNIT =="472U"  | #one large school sp.
                              sample_data$YEAR == "2003" &
                              sample_data$PRIMARY_SAMPLE_UNIT =="119U"  | #one large school sp. 
                              sample_data$YEAR == "2004" &
                              sample_data$PRIMARY_SAMPLE_UNIT =="403U"  | #one large school sp.
                              sample_data$YEAR == "2001" & 
                              sample_data$PRIMARY_SAMPLE_UNIT =="222U"),]
  #dim(sample_data) 5235x8
  
  all_data = inner_join(diversity,sample_data)
  
  mpa_data = all_data %>%
    mutate(MPA_NR= as.numeric(MPA_NR))%>%
    mutate(MPA_NAME = 
             ifelse(MPA_NR == 0| MPA_NR == 27| MPA_NR ==28, 
                    "Not Protected",
                    ifelse(MPA_NR == 1|MPA_NR ==2|MPA_NR ==3|MPA_NR ==4|MPA_NR ==5|MPA_NR ==6|MPA_NR ==7|MPA_NR ==9|MPA_NR ==10|MPA_NR ==11|MPA_NR ==12|MPA_NR ==14|MPA_NR ==15|MPA_NR ==16|MPA_NR ==18|MPA_NR ==21|MPA_NR ==22|MPA_NR ==23, 
                           "Sanctuary Preservation Area",
                           ifelse(MPA_NR ==8|MPA_NR ==13|MPA_NR ==17|MPA_NR ==19, 
                                  "Special Use",
                                  ifelse(MPA_NR == 20, 
                                         "Ecological Reserve", "NA")))))
  
  write_csv(mpa_data, "diversity_data.csv")
  }
  
```

#Plots

```{r plot all diversity by year}

#plot species richness, Simpson, Shannon, and Functional diversity through time 

all_matrices_data = read_csv("diversity_data.csv")
  
#Melt dataframe so diversity indices are in a single column
  x = reshape2::melt(all_matrices_data, id.vars = c("YEAR"),
                     measure.vars=c("richness","shannon","simpson","func.div")) 
#Summarize means and SEs by year and variable
  x=plyr::ddply(x, c("YEAR", "variable"), summarize, value.mean=mean(value), value.se=plotrix::std.error(value))
#Rename levels for figure plotting
  levels(x$variable)=c("Richness", "Shannon", "Simpson", "Functional")
  diversity_plot = x %>%
    as.tibble()
  
  diveristy_year_plot = diversity_plot %>% 
    ggplot(.,aes(x=YEAR, y=value.mean, color=variable))+
    geom_errorbar(aes(ymax=value.mean+value.se,ymin=value.mean-value.se),width=0.2)+
    geom_point(size=1.5)+
    geom_line(aes(group=variable),lwd=1)+
    labs(title= "Florida Keys Reef Fish Biodiversity", x="Year", y="Mean effective \nnumber of species (± SE)", colour = "Diversity index")+
    scale_y_continuous(limits= c(0,50),
                       breaks=c(0,5,10,15,20,25,30,35,40,45,50), 
                       labels=c("0","","10","","20","","30","","40","","50"))+
    scale_x_continuous(limits = c(1999, 2016), breaks = c(2000,2002, 2004, 2006, 2008, 2010, 2012, 2014, 2016), labels=c("2000","","2004","","2008","","2012","","2016"))+
  scale_color_manual(
    labels= c("Richness","Shannon diversity","Simpson diversity","Functional diversity"),
    values=c("Richness"="red",
             "Shannon"="orange",
             "Simpson"="forestgreen",
             "Functional"="blue"))+
  theme_bw()+
  theme(
      legend.position="bottom",
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      #panel.background=element_rect(fill="grey45"),
      axis.title.x=element_text(size=12),
      axis.title.y=element_text(size=12),
      title=element_text(size=12),
      plot.title =element_text(hjust = 0.5),
      legend.text = element_text(size=12),
      legend.title =element_blank())
ggsave(file="diversity_plot.pdf", width=7, height=7, path="plots")

```

```{r plot each diversity by year and no take marine zones}

all_matrices_data = read_csv("diversity_data.csv")

matrices_ntmr = all_matrices_data %>% 
    group_by(YEAR, PROT) %>% #add subregion later 
    summarize(
      richness_mean = mean(richness),
      richness_n = length(richness),
      richness_sd = sd(richness),
      richness_se = richness_sd / sqrt(richness_n),
      richness_min = min(richness),
      richness_max = max(richness),
      shannon_mean = mean(shannon),
      shannon_n = length(shannon),
      shannon_sd = sd(shannon),
      shannon_se = shannon_sd / sqrt(shannon_n),
      shannon_min = min(shannon),
      shannon_max = max(shannon),
      simpson_mean = mean(simpson),
      simpson_n = length(simpson),
      simpson_sd = sd(simpson),
      simpson_se = simpson_sd / sqrt(simpson_n),
      simpson_min = min(simpson),
      simpson_max = max(simpson),
      func.div_mean = mean(func.div),
      func.div_n = length(func.div),
      func.div_sd = sd(func.div),
      func.div_se = func.div_sd / sqrt(func.div_n),
      func.div_min = min(func.div),
      func.div_max = max(func.div),
      evenness_mean = mean(evenness),
      evenness_n = length(evenness),
      evenness_sd = sd(evenness),
      evenness_se = evenness_sd / sqrt(evenness_n),
      evenness_min = min(evenness),
      evenness_max = max(evenness))

#richness
rich_prot = ggplot(matrices_ntmr,aes(x=YEAR,y=richness_mean, colour=factor(PROT), group=factor(PROT)))+ 
  geom_line(aes(group=PROT),lwd=1) +
  geom_point(size=3) +
  geom_errorbar(aes(ymax=richness_mean+richness_se,ymin=richness_mean-richness_se),width=0.1)+
  labs(title= "A) Richness", x="Year", y="Mean effective \nnumber of species (± SE)", color = NULL)+
  scale_color_manual(
    values =  c("blue","red"),
    breaks = c("1", "0"), 
    labels=c("Protected","Not Protected"))+
  scale_x_continuous(
    limits = c(1999, 2016), 
    breaks = c(2000,2002, 2004, 2006, 2008, 2010, 2012, 2014, 2016),
    labels=c("2000","","2004","","2008","","2012","","2016"))+
  theme_bw()+
  theme(
    legend.position="none",
    panel.grid.major=element_blank(),
    panel.grid.minor=element_blank(),
    axis.title.x=element_text(size=12),
    axis.title.y=element_text(size=12),
    title=element_text(size=12))
ggsave(file="richness_by_year_protection.pdf", path="plots")

# shannon
shan_prot = ggplot(matrices_ntmr,aes(x=YEAR,y=shannon_mean, colour=factor(PROT), group=factor(PROT)))+ 
  geom_line(aes(group=PROT),lwd=1) +
  geom_point(size=3) +
  geom_errorbar(aes(ymax=shannon_mean+shannon_se,ymin=shannon_mean-shannon_se),width=0.1)+
  labs(title= "B) Shannon", x="Year", y="Mean effective \nnumber of species (± SE)", color = NULL)+
  scale_color_manual(
    values =  c("blue","red"),
    breaks = c("1", "0"), 
    labels=c("Protected","Not Protected"))+
  scale_x_continuous(
    limits = c(1999, 2016), 
    breaks = c(2000,2002, 2004, 2006, 2008, 2010, 2012, 2014, 2016),
    labels=c("2000","","2004","","2008","","2012","","2016"))+
  theme_bw()+
  theme(
    legend.position="none",
    panel.grid.major=element_blank(),
    panel.grid.minor=element_blank(),
    axis.title.x=element_text(size=12),
    axis.title.y=element_text(size=12),
    title=element_text(size=12))
ggsave(file="shannon_diversity_by_year_protection.pdf", path="plots")

#simpson
simp_prot = ggplot(matrices_ntmr,aes(x=YEAR,y=simpson_mean, colour=factor(PROT), group=factor(PROT)))+ 
  geom_line(aes(group=PROT),lwd=1) +
  geom_point(size=3) +
  geom_errorbar(aes(ymax=simpson_mean+simpson_se,ymin=simpson_mean-simpson_se),width=0.1)+
  labs(title= "C) Simpson", x="Year", y="Mean effective \nnumber of species (± SE)", color = NULL)+
  scale_color_manual(
    values =  c("blue","red"),
    breaks = c("1", "0"), 
    labels=c("Protected","Not Protected"))+
  scale_x_continuous(
    limits = c(1999, 2016), 
    breaks = c(2000,2002, 2004, 2006, 2008, 2010, 2012, 2014, 2016),
    labels=c("2000","","2004","","2008","","2012","","2016"))+
  theme_bw()+
  theme(
    legend.position="none",
    panel.grid.major=element_blank(),
    panel.grid.minor=element_blank(),
    axis.title.x=element_text(size=12),
    axis.title.y=element_text(size=12),
    title=element_text(size=12))
ggsave(file="simpson_diversity_by_year_protection.pdf", path="plots")

# functional
func_prot = ggplot(matrices_ntmr,aes(x=YEAR,y=func.div_mean, colour=factor(PROT), group=factor(PROT)))+ 
  geom_line(aes(group=PROT),lwd=1) +
  geom_point(size=3) +
  geom_errorbar(aes(ymax=func.div_mean+func.div_se,ymin=func.div_mean-func.div_se),width=0.1)+
  labs(title= "D) Functional", x="Year", y="Mean effective \nnumber of species (± SE)", color = NULL)+
  scale_color_manual(
    values =  c("blue","red"),
    breaks = c("1", "0"), 
    labels=c("Protected","Not Protected"))+
  scale_x_continuous(
    limits = c(1999, 2016), 
    breaks = c(2000,2002, 2004, 2006, 2008, 2010, 2012, 2014, 2016),
    labels=c("2000","","2004","","2008","","2012","","2016"))+
  theme_bw()+
  theme(
    legend.position="none",
    panel.grid.major=element_blank(),
    panel.grid.minor=element_blank(),
    axis.title.x=element_text(size=12),
    axis.title.y=element_text(size=12),
    title=element_text(size=12))
ggsave(file="functional_diversity_by_year_protection.pdf", path="plots")

for_legend_prot_horiz = ggplot(matrices_ntmr,aes(x=YEAR,y=richness_mean, colour=factor(PROT), group=factor(PROT)))+ 
  geom_line(aes(group=factor(PROT)),lwd=1) +
  geom_point(size=3) +
  labs(colour = "")+
  scale_colour_manual(labels=c("Protected", "Not Protected"), values= c("red", "blue"))+
    theme(
      legend.position="bottom", #"none", "right",c(0.8,0.68),
      legend.text=element_text(size=11),
      legend.key.size=unit(5,"mm"))
legend_prot_horiz <- get_legend(for_legend_prot_horiz)

#all plots on one page
g_prot <- grid.arrange(rich_prot,shan_prot,simp_prot,func_prot)

ggsave(file="all_indices_by_year_and_protection.pdf", g_prot, width=10, height=7, path="plots")

```

Plot diversity indices by grouped strata 

```{r plot by each diversity by year and grouped strata}

all_matrices_data = read_csv("diversity_data.csv")

matrices_strat_grouped = all_matrices_data %>% 
    mutate(
      STRAT_GROUPED = 
      ifelse(grepl("FMLR|FSLR|FDLR", STRAT), 'LINEAR_REEF', 
             ifelse(grepl("OFPR|MCPR|INPR", STRAT), 'PATCH_REEF',
                    ifelse(grepl('HRRF', STRAT), 'HIGH_RELIEF', "IDK")))) %>%
    group_by(YEAR, STRAT_GROUPED) %>% 
    summarize(
      richness_mean = mean(richness),
      richness_n = length(richness),
      richness_sd = sd(richness),
      richness_se = richness_sd / sqrt(richness_n),
      richness_min = min(richness),
      richness_max = max(richness),
      shannon_mean = mean(shannon),
      shannon_n = length(shannon),
      shannon_sd = sd(shannon),
      shannon_se = shannon_sd / sqrt(shannon_n),
      shannon_min = min(shannon),
      shannon_max = max(shannon),
      simpson_mean = mean(simpson),
      simpson_n = length(simpson),
      simpson_sd = sd(simpson),
      simpson_se = simpson_sd / sqrt(simpson_n),
      simpson_min = min(simpson),
      simpson_max = max(simpson),
      func.div_mean = mean(func.div),
      func.div_n = length(func.div),
      func.div_sd = sd(func.div),
      func.div_se = func.div_sd / sqrt(func.div_n),
      func.div_min = min(func.div),
      func.div_max = max(func.div),
      evenness_mean = mean(evenness),
      evenness_n = length(evenness),
      evenness_sd = sd(evenness),
      evenness_se = evenness_sd / sqrt(evenness_n),
      evenness_min = min(evenness),
      evenness_max = max(evenness))

#richness
rich_gs= ggplot(matrices_strat_grouped,aes(x=YEAR,y=richness_mean, colour=STRAT_GROUPED, group=STRAT_GROUPED))+ #shape=STRAT
  geom_line(aes(group=STRAT_GROUPED),lwd=1) +
  geom_point(size=3) +
 geom_errorbar(aes(ymin=richness_mean-richness_se, ymax=richness_mean+richness_se), width=.1)+
  labs(title= "A) Richness", x="Year", y="Mean effective \nnumber of species (± SE)", colour = "Strata")+
  scale_colour_manual(labels=c("High reef", "Linear reef", "Patch reef"), values= c("red", "green", "blue"))+
  scale_x_continuous(limits = c(1999, 2016), breaks = c(2000,2002, 2004, 2006, 2008, 2010, 2012, 2014, 2016), labels=c("2000","","2004","","2008","","2012","","2016"))+
  theme_bw()+
  theme(
      legend.position="none",
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      axis.title.x=element_text(size=12),
      axis.title.y=element_text(size=12),
      title=element_text(size=12))
ggsave(file="richness_by_year_and_strata_grouped.pdf", path="plots")

#shannon
shan_gs= ggplot(matrices_strat_grouped,aes(x=YEAR,y=shannon_mean, colour=STRAT_GROUPED, group=STRAT_GROUPED))+ #shape=STRAT
  geom_line(aes(group=STRAT_GROUPED),lwd=1) +
  geom_point(size=3) +
  geom_errorbar(aes(ymin=shannon_mean-shannon_se, ymax=shannon_mean+shannon_se), width=.1)+
  labs(title= "B) Shannon", x="Year", y="Mean effective \nnumber of species (± SE)", colour = "Strata")+
  scale_colour_manual(labels=c("High reef", "Linear reef", "Patch reef"), values= c("red", "green", "blue"))+
  scale_x_continuous(limits = c(1999, 2016), breaks = c(2000,2002, 2004, 2006, 2008, 2010, 2012, 2014, 2016), labels=c("2000","","2004","","2008","","2012","","2016"))+
  theme_bw()+
  theme(
      legend.position="none",
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      axis.title.x=element_text(size=12),
      axis.title.y=element_text(size=12),
      title=element_text(size=12))
ggsave(file="shannon_by_year_and_strata_grouped.pdf", path="plots")

#simpson
sim_gs= ggplot(matrices_strat_grouped,aes(x=YEAR,y=simpson_mean, colour=STRAT_GROUPED, group=STRAT_GROUPED))+ #shape=STRAT
  geom_line(aes(group=STRAT_GROUPED),lwd=1) +
  geom_point(size=3) +
  geom_errorbar(aes(ymin=simpson_mean-simpson_se, ymax=simpson_mean+simpson_se), width=.1)+
  labs(title= "C) Simpson", x="Year", y="Mean effective \nnumber of species (± SE)", colour = "Strata")+
  scale_colour_manual(labels=c("High reef", "Linear reef", "Patch reef"), values= c("red", "green", "blue"))+
  scale_x_continuous(limits = c(1999, 2016), breaks = c(2000,2002, 2004, 2006, 2008, 2010, 2012, 2014, 2016), labels=c("2000","","2004","","2008","","2012","","2016"))+
  theme_bw()+
  theme(
      legend.position="none",
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      axis.title.x=element_text(size=12),
      axis.title.y=element_text(size=12),
      title=element_text(size=12))
ggsave(file="simpson_by_year_and_strata_grouped.pdf", path="plots")

#functional
func_gs= ggplot(matrices_strat_grouped,aes(x=YEAR,y=func.div_mean, colour=STRAT_GROUPED, group=STRAT_GROUPED))+ #shape=STRAT
  geom_line(aes(group=STRAT_GROUPED),lwd=1) +
  geom_point(size=3) +
  geom_errorbar(aes(ymax=func.div_mean+func.div_se,ymin=func.div_mean-func.div_se),width=0.1)+
  labs(title= "D) Functional", x="Year", y="Mean effective \nnumber of species (± SE)", colour = "Strata")+
  scale_colour_manual(labels=c("High reef", "Linear reef", "Patch reef"), values= c("red", "green", "blue"))+
  scale_x_continuous(limits = c(1999, 2016), breaks = c(2000,2002, 2004, 2006, 2008, 2010, 2012, 2014, 2016), labels=c("2000","","2004","","2008","","2012","","2016"))+
  theme_bw()+
  theme(
      legend.position="none",
      panel.grid.major=element_blank(),
      panel.grid.minor=element_blank(),
      axis.title.x=element_text(size=12),
      axis.title.y=element_text(size=12),
      title=element_text(size=12))
ggsave(file="functional_by_year_and_strata_grouped.pdf", path="plots")

for_legend_gs_horiz = ggplot(matrices_strat_grouped,aes(x=YEAR,y=richness_mean, colour=STRAT_GROUPED, group=STRAT_GROUPED))+ 
  geom_line(aes(group=STRAT_GROUPED),lwd=1) +
  geom_point(size=3) +
  labs(colour = "Strata")+
  scale_colour_manual(labels=c("High reef", "Linear reef", "Patch reef"), values= c("red", "green", "blue"))+
    theme(
      legend.position="bottom", #"none", "right",c(0.8,0.68),
      legend.text=element_text(size=11),
      legend.key.size=unit(5,"mm"))
legend_gs_horiz <- get_legend(for_legend_gs_horiz)

#all plots on one page
g_gs <- grid.arrange(rich_gs,shan_gs,sim_gs,func_gs,ncol=2)
ggsave(file="all_indices_by_year_and_strata_grouped.pdf", g_gs, width=10, height=7, path="plots")

```

#Statistical tests

```{r test for assumptions of normality }

all_matrices_data = read_csv("diversity_data.csv")

# Manipulate data frame to get total number of PSUs sampled per YEAR and STRATA and also get total PSUs sampled for each YEAR
diversity_data = all_matrices_data

diversity_data$dum1 <- 1
diversity_data_sum1 <- d_fk %>% group_by(YEAR,STRAT,PRIMARY_SAMPLE_UNIT) %>% summarise(sum1=sum(dum1))
diversity_data_sum1$dum2 <- 1
diversity_data_sum2 <- diversity_data_sum1 %>% group_by(YEAR,STRAT) %>% summarise(sum2=sum(dum2))
diversity_data_sum3 <- dcast(d_fk_sum2, YEAR ~ STRAT, value.var="sum2")
diversity_data_sum3$total <- rowSums(diversity_data_sum3[,-1], na.rm=TRUE)
write.csv(diversity_data_sum3, 'fk_sample_summary.csv',row.names=FALSE) 

diversity_data = diversity_data %>%
  group_by(YEAR,PRIMARY_SAMPLE_UNIT, STRAT)

# 1. Run ANOVA to get residuals so we can use them to test assumptions of normality and equal variances
diversity_data$fYEAR <- as.factor(diversity_data$YEAR) # categorical variables are factors
diversity_data$fSTRAT <- as.factor(diversity_data$STRAT) # categorical variables are factors

#Richness

# since there might be an interaction between YEAR and STRAT (i.e., diversity may not change through time consistently across strata or vice versa) use "*" in your model to include an interaction term
richness_aov <- aov(richness~fYEAR*fSTRAT, data=diversity_data) 
diversity_data$resids_rich <- residuals(richness_aov) # get residuals
diversity_data$pred_val_rich <- predict(richness_aov) # get predicted values

#Shannon 
shannon_aov <- aov(shannon~fYEAR*fSTRAT, data=diversity_data)
diversity_data$resids_shan <- residuals(shannon_aov) # get residuals
diversity_data$pred_val_shan <- predict(shannon_aov) # get predicted values

#Simpson
simpson_aov <- aov(simpson~fYEAR*fSTRAT, data=diversity_data)
diversity_data$resids_simp <- residuals(simpson_aov) # get residuals
diversity_data$pred_val_simp <- predict(simpson_aov) # get predicted values

#Functional
func_aov <- aov(func.div~fYEAR*fSTRAT, data=diversity_data)
diversity_data$resids_func <- residuals(func_aov) # get residuals
diversity_data$pred_val_func <- predict(func_aov) # get predicted values

# 2. Examine plots of residuals to qualitatively check for normality and equal variances
ggplot() + geom_density(aes(x=diversity_data$resids_rich)) # look at distribution of residuals
#distribution looks good
plot(richness_aov)
# plot 1: Residuals vs Fitted values - data points should be distibuted evenly above and below the line and across the plot...if they are not, this indicates a violation of assumptions
  # plot 2: Q-Q plot - data points\ should fall more or less along dashed line...if they do not, this indicates a violation of assumptions
#looks good

ggplot() + geom_density(aes(x=diversity_data$resids_shan))
#distribution looks good
plot(shannon_aov)
#residual verse fitted more in the middle than left or right
#Q-Q plot looks alright

ggplot() + geom_density(aes(x=diversity_data$resids_simp))
#distribution looks good
plot(simpson_aov)
#residual verse fitted more in the middle and right than left
#Q-Q plot looks alright

ggplot() + geom_density(aes(x=diversity_data$resids_func))
#distribution looks good
plot(func_aov)
#residual verse fitted looks pretty good
#Q-Q plot looks alright 

# 3 Shapiro-Wilk test - p-value < 0.05 means the data are NOT normally distributed

#richness
diversity_data %$% shapiro.test(resids_rich[1:5000]) 
#W = 0.99298, p-value = 5.484e-15
#Not normally distributed 

#shannon
diversity_data %$% shapiro.test(resids_shan[1:5000]) 
#W = 0.99963, p-value = 0.5044


#simpson
diversity_data %$% shapiro.test(resids_simp[1:5000]) 
#W = 0.99474, p-value = 1.587e-12
#Not normally distributed

#functional
diversity_data %$% shapiro.test(resids_func[1:5000]) 
#W = 0.99699, p-value = 1.816e-08
#Not normally distributed

# 4 Test for skew - greater than zero is evidence for having skew; 
#test with t-test - p-value < 0.05 means data are skewed

# richness
skewness(diversity_data$resids_rich) #-0.3158723
t<- skewness(diversity_data$resids_rich) %>%
  divide_by(sqrt(6/length(diversity_data$resids_rich))) # t-value -9.330271
# probability of the t-value by chance alone when skew is zero; pt=cummulative density function of t-dist, first number=calculated t-value; second=df
1-pt(t,length(diversity_data$resids_rich)) 
#p=1
#distribution of residuals is NOT significantly skewed

# shannon
skewness(diversity_data$resids_shan) #0.02177687 (greater than zero so skewed)
t<- skewness(diversity_data$resids_shan) %>%
  divide_by(sqrt(6/length(diversity_data$resids_shan))) # t-value 0.6432476
1-pt(t,length(diversity_data$resids_shan)) #p-value=0.2600458, greater than 0.05
# distribution of residuals is NOT significantly skewed
  
#Simpson
skewness(diversity_data$resids_simp) #0.27978 (greater than zero so skewed)
t<- skewness(diversity_data$resids_simp) %>% 
  divide_by(sqrt(6/length(diversity_data$resids_simp))) # t-value 8.264173
1-pt(t,length(diversity_data$resids_simp)) #p=1.110223e-16, not greater than 0.05
# distribution of residuals ARE significantly skewed
  
#Functional
skewness(diversity_data$resids_func) #-0.2158813 (not skewed)
t<- skewness(diversity_data$resids_func) %>%
  divide_by(sqrt(6/length(diversity_data$resids_func))) # t-value -6.376726
1-pt(t,length(diversity_data$resids_func)) #1, 
# distribution of residuals is NOT significantly skewed

#4 Bartlett test - p-value < 0.05 means data do not have equal variances across groups
#Richness
bartlett.test(diversity_data$resids_rich~diversity_data$fYEAR)
#Bartlett's K-squared = 80.132, df = 15, p-value = 6.608e-11
bartlett.test(diversity_data$resids_rich~diversity_data$fSTRAT)
#Bartlett's K-squared = 110.04, df = 6, p-value < 2.2e-16
# variances of residuals are significantly different among groups for both YEAR and STRAT

#Shannon
bartlett.test(diversity_data$resids_shan~diversity_data$fYEAR)
#Bartlett's K-squared = 40.706, df = 15, p-value = 0.0003545
bartlett.test(diversity_data$resids_shan~diversity_data$fSTRAT)
#Bartlett's K-squared = 37.594, df = 6, p-value = 1.348e-06
# variances of residuals are significantly different among groups for both YEAR and STRAT

#Simpson
bartlett.test(diversity_data$resids_simp~diversity_data$fYEAR)
#Bartlett's K-squared = 28.603, df = 15, p-value = 0.01809
bartlett.test(diversity_data$resids_simp~diversity_data$fSTRAT)
#Bartlett's K-squared = 62.452, df = 6, p-value = 1.427e-11
# variances of residuals are significantly different among groups for both YEAR and STRAT

#Functional
bartlett.test(diversity_data$resids_func~diversity_data$fYEAR)
#Bartlett's K-squared = 43.096, df = 15, p-value = 0.0001521
bartlett.test(diversity_data$resids_func~diversity_data$fSTRAT)
#Bartlett's K-squared = 43.44, df = 6, p-value = 9.542e-08
# variances of residuals are significantly different among groups for both YEAR and STRAT

#Data are not normally distributed (except shannon),skewed, and have unequal variances  

```

Transform data to better meet the assumptions of normality using Boxcox method 

```{r transform data}

# richness
diversity_data %>%
  boxcox(richness~fYEAR, data = .) %$%
  x[which.max(y)] #x is lambda and y is values of likelihood
# x = 1.353535; this output is the lambda value that you should use to transform data
diversity_data %>%
  boxcox(richness~fSTRAT, data = .) %$%
  x[which.max(y)] #x is lambda and y is values of likelihood
# x = 1.434343
diversity_data <- diversity_data %>% mutate(richness_bc = (richness %>%
  raise_to_power(1.39) %>% subtract(1) %>% divide_by(1.39))) # since x for YEAR and STRAT were so similar, I used something in between; use x/lambda in raise_to_power() and divide_by()

# shannon
diversity_data %>%
  boxcox(shannon~fYEAR, data = .) %$%
  x[which.max(y)] #x is lambda and y is values of likelihood
# x = 0.9090909; this output is the lambda value that you should use to transform data
diversity_data %>%
  boxcox(shannon~fSTRAT, data = .) %$%
  x[which.max(y)] #x is lambda and y is values of likelihood
# x = 0.9090909
diversity_data <- diversity_data %>% mutate(shannon_bc = (shannon %>%
  raise_to_power(.9) %>% subtract(1) %>% divide_by(.9))) # use x/lambda in raise_to_power() and divide_by()

# simpson
diversity_data %>%
  boxcox(simpson~fYEAR, data = .) %$%
  x[which.max(y)] #x is lambda and y is values of likelihood
# x = 0.6666667; this output is the lambda value that you should use to transform data
diversity_data %>%
  boxcox(simpson~fSTRAT, data = .) %$%
  x[which.max(y)] #x is lambda and y is values of likelihood
# x = 0.6666667
diversity_data <- diversity_data %>% mutate(simpson_bc = (simpson %>%
  raise_to_power(.67) %>% subtract(1) %>% divide_by(.67))) # use x/lambda in raise_to_power() and divide_by()

#Functional
diversity_data %>%
  boxcox(func.div~fYEAR, data = .) %$%
  x[which.max(y)] #x is lambda and y is values of likelihood
# x =  1.555556; this output is the lambda value that you should use to transform data
diversity_data %>%
  boxcox(func.div~fSTRAT, data = .) %$%
  x[which.max(y)] #x is lambda and y is values of likelihood
# x = 1.555556
diversity_data <- diversity_data %>% mutate(func.div_bc = (func.div %>%
  raise_to_power(1.56) %>% subtract(1) %>% divide_by(1.56))) # use x/lambda in raise_to_power() and divide_by()

# Retest assumptions with boxcox transformed data 

# 1. Run ANOVA to get residuals so we can use them to test assumptions of normality and equal variances


#Richness
# since there might be an interaction between YEAR and STRAT (i.e., diversity may not change through time consistently across strata or vice versa) use "*" in your model to include an interaction term
richness_aov <- aov(richness_bc~fYEAR*fSTRAT, data=diversity_data) 
diversity_data$resids_rich_bc <- residuals(richness_aov) # get residuals
diversity_data$pred_val_rich_bc <- predict(richness_aov) # get predicted values

#Shannon 
shannon_aov <- aov(shannon_bc~fYEAR*fSTRAT, data=diversity_data)
diversity_data$resids_shan_bc <- residuals(shannon_aov) # get residuals
diversity_data$pred_val_shan_bc <- predict(shannon_aov) # get predicted values

#Simpson
simpson_aov <- aov(simpson_bc~fYEAR*fSTRAT, data=diversity_data)
diversity_data$resids_simp_bc <- residuals(simpson_aov) # get residuals
diversity_data$pred_val_simp_bc <- predict(simpson_aov) # get predicted values

#Functional
func_aov <- aov(func.div_bc~fYEAR*fSTRAT, data=diversity_data)
diversity_data$resids_func_bc <- residuals(func_aov) # get residuals
diversity_data$pred_val_func_bc <- predict(func_aov) # get predicted values

# 2. Examine plots of residuals to qualitatively check for normality and equal variances
ggplot() + geom_density(aes(x=diversity_data$resids_rich_bc)) # look at distribution of residuals
#distribution looks good
plot(richness_aov)
# plot 1: Residuals vs Fitted values - data points should be distibuted evenly above and below the line and across the plot...if they are not, this indicates a violation of assumptions
  # plot 2: Q-Q plot - data points\ should fall more or less along dashed line...if they do not, this indicates a violation of assumptions
#looks good
ggplot(data = diversity_data) + geom_boxplot(mapping = aes(x = STRAT, y = richness_bc)) + facet_wrap(~YEAR, scales="free_y")

ggplot() + geom_density(aes(x=diversity_data$resids_shan_bc))
#distribution looks good
plot(shannon_aov)
#residual verse fitted more in the middle than left or right
#Q-Q plot looks alright

ggplot() + geom_density(aes(x=diversity_data$resids_simp_bc))
#distribution looks good
plot(simpson_aov)
#residual verse fitted more to the right than left
#Q-Q plot looks alright

ggplot() + geom_density(aes(x=diversity_data$resids_func_bc))
#distribution looks good
plot(func_aov)
#residual verse fitted looks pretty good
#Q-Q plot looks alright 

# 3 Shapiro-Wilk test - p-value < 0.05 means the data are NOT normally distributed

#richness
diversity_data %$% shapiro.test(resids_rich_bc[1:5000]) 
#W = 0.99931, p-value = 0.05026
#Normally distributed 

#shannon
diversity_data %$% shapiro.test(resids_shan_bc[1:5000]) 
#W = 0.9994, p-value = 0.1046
#Normally distributed

#simpson
diversity_data %$% shapiro.test(resids_simp_bc[1:5000]) 
#W = 0.99921, p-value = 0.02236
#Not normally distributed

#functional
diversity_data %$% shapiro.test(resids_func_bc[100:5000]) 
#W = 0.99921, p-value = 0.02295
#Not normally distributed

# 4 Test for skew - greater than zero is evidence for having skew; 
#test with t-test - p-value < 0.05 means data are skewed

# richness
skewness(diversity_data$resids_rich_bc) #-0.01965892 - not skewed 
t<- skewness(diversity_data$resids_rich_bc) %>%
  divide_by(sqrt(6/length(diversity_data$resids_rich_bc))) # t-value --0.58068731
# probability of the t-value by chance alone when skew is zero; pt=cummulative density function of t-dist, first number=calculated t-value; second=df
1-pt(t,length(diversity_data$resids_rich_bc)) 
#p=0.7192619
#distribution of residuals are NOT significantly skewed

# shannon
skewness(diversity_data$resids_shan_bc) #-0.06922674 (less than zero so skewed)
t<- skewness(diversity_data$resids_shan_bc) %>%
  divide_by(sqrt(6/length(diversity_data$resids_shan_bc))) # t-value 0.6432476
1-pt(t,length(diversity_data$resids_shan_bc)) #p-value=0.9795391, greater than 0.05
# distribution of residuals are NOT significantly skewed
  
#Simpson
skewness(diversity_data$resids_simp_bc) #-0.04830602 (less than zero so skewed)
t<- skewness(diversity_data$resids_simp_bc) %>% 
  divide_by(sqrt(6/length(diversity_data$resids_simp_bc))) # t-value 
1-pt(t,length(diversity_data$resids_simp)) #p=0.9231613
# distribution of residuals are NOT significantly skewed
  
#Functional
skewness(diversity_data$resids_func_bc) #-0.0475052 (less than zero so skewed)
t<- skewness(diversity_data$resids_func_bc) %>%
  divide_by(sqrt(6/length(diversity_data$resids_func_bc))) # t-value 
1-pt(t,length(diversity_data$resids_func_bc)) #0.9196938
# distribution of residuals are NOT significantly skewed

#4 Bartlett test - p-value < 0.05 means data do not have equal variances across groups
#Richness
bartlett.test(diversity_data$resids_rich_bc~diversity_data$fYEAR)
#Bartlett's K-squared = 58.753, df = 15, p-value = 4.127e-07
bartlett.test(diversity_data$resids_rich_bc~diversity_data$fSTRAT)
#Bartlett's K-squared = 68.924, df = 6, p-value = 6.794e-13
# variances of residuals are significantly different among groups for both YEAR and STRAT

#Shannon
bartlett.test(diversity_data$resids_shan_bc~diversity_data$fYEAR)
#Bartlett's K-squared = 43.224, df = 15, p-value = 0.0001453
bartlett.test(diversity_data$resids_shan_bc~diversity_data$fSTRAT)
#Bartlett's K-squared = 34.477, df = 6, p-value = 5.441e-06
# variances of residuals are significantly different among groups for both YEAR and STRAT

#Simpson
bartlett.test(diversity_data$resids_simp_bc~diversity_data$fYEAR)
#Bartlett's K-squared = 30.61, df = 15, p-value = 0.009901
bartlett.test(diversity_data$resids_simp_bc~diversity_data$fSTRAT)
#Bartlett's K-squared = 42.733, df = 6, p-value = 1.317e-07
# variances of residuals are significantly different among groups for both YEAR and STRAT

#Functional
bartlett.test(diversity_data$resids_func_bc~diversity_data$fYEAR)
#Bartlett's K-squared = 37.139, df = 15, p-value = 0.001208
bartlett.test(diversity_data$resids_func_bc~diversity_data$fSTRAT)
#Bartlett's K-squared = 39.931, df = 6, p-value = 4.7e-07
# variances of residuals are significantly different among groups for both YEAR and STRAT

#Data are not normally distributed (except shannon),skewed, and have unequal variances  proceed with non-parametric tests 

```

nonparametric Kruskal-Wallis test for significance by level of protection 

```{r Kruskal-Wallis test for indices by protection}

all_matrices_data = read_csv("diversity_data.csv")

all_matrices_data$PROT = factor(all_matrices_data$PROT, levels=c("0","1"))
levels(all_matrices_data$PROT)

#richness 
kruskal.test(all_matrices_data$richness~all_matrices_data$PROT)
#Kruskal-Wallis chi-squared = 111.72, df = 1, p-value < 2.2e-16

#Shannon 
kruskal.test(all_matrices_data$shannon~all_matrices_data$PROT)
#Kruskal-Wallis chi-squared = 33.185, df = 1, p-value = 8.377e-09

#Simpson 
kruskal.test(all_matrices_data$simpson~all_matrices_data$PROT)
#Kruskal-Wallis chi-squared = 26.378, df = 1, p-value = 2.808e-07

#Functional
kruskal.test(all_matrices_data$func.div~all_matrices_data$PROT)
#Kruskal-Wallis chi-squared = 26.496, df = 1, p-value = 2.641e-07

## All indices are significantly different by level of protection

```

Dunn's test between type of no take zones 
```{r Dunn's test for indices by differnt types of zones}

all_matrices_data = read_csv("diversity_data.csv")

all_matrices_data$MPA_NAME = factor(all_matrices_data$MPA_NAME, levels=c("Not Protected",               "Sanctuary Preservation Area","Ecological Reserve","Special Use"))
levels(all_matrices_data$MPA_NAME)

#richness 
kruskal.test(all_matrices_data$richness~all_matrices_data$MPA_NAME)
#Kruskal-Wallis chi-squared = 164.29, df = 3, p-value < 2.2e-16
dt_rich_mpa = dunnTest(richness~MPA_NAME, data=all_matrices_data)
dt_richnnes_mpa = dt_rich_mpa$res

cldList(P.adj~Comparison,
        data = dt_richnnes_mpa,
        threshold = 0.05)
#ER = Not Protected
#SPA = SU

#Shannon 
kruskal.test(all_matrices_data$shannon~all_matrices_data$MPA_NAME)
#Kruskal-Wallis chi-squared = 37.113, df = 3, p-value = 4.355e-08
dt_shan_mpa = dunnTest(shannon~MPA_NAME, data=all_matrices_data)
dt_shannon_mpa = dt_shan_mpa$res

cldList(P.adj~Comparison,
        data = dt_shannon_mpa,
        threshold = 0.05)
#ER=Not Protected
#ER=SU
#SPA=SU 

#Simpson 
kruskal.test(all_matrices_data$simpson~all_matrices_data$MPA_NAME)
#Kruskal-Wallis chi-squared = 27.878, df = 3, p-value = 3.852e-06
dt_simp_mpa = dunnTest(simpson~MPA_NAME, data=all_matrices_data)
dt_simpson_mpa = dt_simp_mpa$res

cldList(P.adj~Comparison,
        data = dt_simpson_mpa,
        threshold = 0.05)
#ER=Not Protected
#ER=SU
#ER=SPA 
#SPA=SU 

#Functional
kruskal.test(all_matrices_data$func.div~all_matrices_data$MPA_NAME)
#Kruskal-Wallis chi-squared = 32.542, df = 3, p-value = 4.022e-07
dt_fd_mpa = dunnTest(func.div~MPA_NAME, data=all_matrices_data)
dt_functional_mpa = dt_fd_mpa$res

cldList(P.adj~Comparison,
        data = dt_functional_mpa,
        threshold = 0.05)
#ER=SPA
#ER=SU
#SU=SPA
#Not protected not significanyly similar to anything 

## All indices are significantly different by level of protection

```

Dunn's test by strata 

```{r Dunn's test by strata}

all_matrices_data = read_csv("diversity_data.csv") 

all_matrices_data$STRAT = factor(all_matrices_data$STRAT, levels=c("FMLR", "FSLR", "HRRF", "OFPR", "MCPR", "INPR", "FDLR"))
levels(all_matrices_data$STRAT)

#richness
kruskal.test(all_matrices_data$richness~all_matrices_data$STRAT)
#Kruskal-Wallis chi-squared = 1172.2, df = 6, p-value < 2.2e-16
dt_rich_strat = dunnTest(richness~STRAT, data=all_matrices_data)
dt_richnnes_strat = dt_rich_strat$res

cldList(P.adj~Comparison,
        data = dt_richnnes_strat,
        threshold = 0.05)
#FMLR = OFPR 

#Shannon strata
kruskal.test(all_matrices_data$shannon~all_matrices_data$STRAT)
#Kruskal-Wallis chi-squared = 457.3, df = 6, p-value < 2.2e-16
dt_shan_strat = dunnTest(shannon~STRAT, data=all_matrices_data)
dt_shannon_strat = dt_shan_strat$res

cldList(P.adj~Comparison,
        data = dt_shannon_strat,
        threshold = 0.05)
#FDLR=FSLR
#FDLR=INPR
#FMLR=MCPR

#Simpson 
kruskal.test(all_matrices_data$simpson~all_matrices_data$STRAT)

dt_simp_strat = dunnTest(simpson~STRAT, data=all_matrices_data)
dt_simpson_strat = dt_simp_strat$res
#Kruskal-Wallis chi-squared = 363.58, df = 6, p-value < 2.2e-16
cldList(P.adj~Comparison,
        data = dt_simpson_strat,
        threshold = 0.05)
#FDLR=INPR 
#FMLR=FSLR 
#HRRF=OFPR

#Functional  
kruskal.test(all_matrices_data$func.div~all_matrices_data$STRAT)
#Kruskal-Wallis chi-squared = 706.22, df = 6, p-value < 2.2e-16
dt_fd_strat = dunnTest(func.div~STRAT, data=all_matrices_data)
dt_functional_strat = dt_fd_strat$res

cldList(P.adj~Comparison,
        data = dt_functional_strat,
        threshold = 0.05)
#FDLR=HRRF
#FDLR=MCPR 
#INPR=OFPR 

DunnTest_strata = cbind(dt_richnnes_strat, dt_simpson_strat, dt_shannon_strat, dt_functional_strat)

write_csv(DunnTest_strata, "DunnTest_strata.csv") 

```

Dunn's test by year 

```{r Dunn's test by year}

all_matrices_data$YEAR = factor(all_matrices_data$YEAR, levels=c("1999", "2000","2001","2002","2003","2004","2005","2006","2007","2008","2009","2010","2011","2012","2014","2016"))
levels(all_matrices_data$YEAR)

#richness
kruskal.test(all_matrices_data$richness~all_matrices_data$YEAR)
#Kruskal-Wallis chi-squared = 199.14, df = 15, p-value < 2.2e-16

dt_rich_year = dunnTest(richness~YEAR, data=all_matrices_data)
dt_richnnes_year = dt_rich_year$res

cldList(P.adj~Comparison,
        data = dt_richnnes_year,
        threshold = 0.05)

#Shannon strata
kruskal.test(all_matrices_data$shannon~all_matrices_data$YEAR)

dt_shan_year = dunnTest(shannon~YEAR, data=all_matrices_data)
dt_shannon_year = dt_shan_year$res

cldList(P.adj~Comparison,
        data = dt_shannon_year,
        threshold = 0.05)

#Simpson 
kruskal.test(all_matrices_data$simpson~all_matrices_data$YEAR)

dt_simp_year = dunnTest(simpson~YEAR, data=all_matrices_data)
dt_simpson_year = dt_simp_year$res

cldList(P.adj~Comparison,
        data = dt_simpson_year,
        threshold = 0.05)

#Functional  
kruskal.test(all_matrices_data$func.div~all_matrices_data$YEAR)

dt_fd_year = dunnTest(func.div~YEAR, data=all_matrices_data)
dt_functional_year = dt_fd_year$res

cldList(P.adj~Comparison,
        data = dt_functional_year,
        threshold = 0.05)

DunnTest_year = cbind(dt_richnnes_year, dt_simpson_year, dt_shannon_year, dt_functional_year)

write_csv(DunnTest_year, "DunnTest_year.csv") 

```

Diversity between SPA, SU, ER 

"mapNumber" =  
    0	Unprotected                 [unprotected]
    1	Carysfort                   [Carysfort Sanctuary Preservation Area]
    2	Elbow                       [Elbow Sanctuary Preservation Area]
    3	Key_Largo_Dry_Rocks         [Key Largo Dry Rocks Sanctuary Preservation Area]
    4	Grecian_Rocks               [Grecian Rocks Sanctuary Preservation Area]
    5	French                      [French Reef Sanctuary Preservation Area]
    6	Molasses                    [Molasses Reef Sanctuary Preservation Area]
    7	Conch_Reef                  [Conch Reef Sanctuary Preservation Area]
    8	Conch_RO                    [Conch Reef Research Only Area]
    9	Davis                       [Davis Reef Sanctuary Preservation Area]
    10 Hen_Chickens               [Hen and Chickens Sanctuary Preservation Area]
    11 Cheeca_Rocks               [Cheeca Rocks Sanctuary Preservation Area]
    12 Alligator                  [Alligator Reef Sanctuary Preservation Area]
    13 Tennessee                  [Tennesse Reef Research Only Area]
    14 Coffins_Patch              [Coffins Patch Sanctuary Preservation Area]
    15 Sombrero                   [Sombrero Key Sanctuary Preservation Area]
    16 Looe_Key                   [Looe Key Sanctuary Preservation Area]
    17 Looe_RO                    [Looe Key Research Only Area]
    18 Newfound_Harbor            [Newfound Harbor Key Sanctuary Preservation Area]
    19 East_Sambo                 [Eastern Sambo Research Only Area]
    20 West_Sambo                 [Western Sambo Ecological Reserve]
    21 East_Dry_Rocks             [Eastern Dry Rocks Sanctuary Preservation Area]
    22 Rock_Key                   [Rock Key Sanctuary Preservation Area]
    23 Sand_Key                   [Sand Key Sanctuary Preservation Area]
    24 North Ecological Reserve   [Tortugas North Ecological Reserve]
    25 South Ecological Reserve   [Tortugas South Ecological Reserve]
    26 Research Natural Area      [unprotected]
    27 Not Protected              [unprotected]
    28 Not Protected              [unprotected]

```{r bargraph of diversity among different NTMR}

all_matrices_data = read_csv("diversity_data.csv")

diversity_ntmr = reshape2::melt(all_matrices_data, id.vars = c("MPA_NAME"),
                                measure.vars=c("richness","shannon","simpson","func.div"))

diversity_ntmr=plyr::ddply(diversity_ntmr, c("MPA_NAME", "variable"), summarize, 
                           value.mean=mean(value),
                           value.se=plotrix::std.error(value))
levels(diversity_ntmr$variable)=c("Richness", "Shannon", "Simpson", "Functional")

as.tibble(diversity_ntmr)

diversity_ntmr_plot = diversity_ntmr %>%
  ggplot(.,aes(x=MPA_NAME, y=value.mean,color=variable, group=variable, fill=variable))+ # 
  geom_errorbar(aes(ymax=value.mean+value.se, ymin=value.mean-value.se), size=.6,width=0.3,position=position_dodge(.9))+
  geom_bar(position="dodge",stat="identity", color="black",size=.3)+
  labs(title="Biodiversity by Different Marine Zones", x="", y="Mean effective \nnumber of species (± SE)",color="",fill="")+
  theme(
    legend.position = "right",
    legend.title=element_blank(),
    axis.title.x=element_text(size=12),
    axis.title.y=element_text(size=12),
    legend.text=element_text(size=12),
    plot.title=element_text(hjust=0.5))

ggsave(file="diversity_by_level_of_protection.pdf",diversity_ntmr_plot, width=10,height=4, path="plots")
  
```